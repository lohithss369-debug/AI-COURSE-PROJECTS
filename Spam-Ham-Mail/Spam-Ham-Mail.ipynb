{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af803aea-a7c9-422c-a2e0-9ef5d3025172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on test set:\n",
      "Accuracy: 0.989464245684824\n",
      "ROC AUC: 0.9996492553963414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      2231\n",
      "        spam       0.99      0.99      0.99      2230\n",
      "\n",
      "    accuracy                           0.99      4461\n",
      "   macro avg       0.99      0.99      0.99      4461\n",
      "weighted avg       0.99      0.99      0.99      4461\n",
      "\n",
      "\n",
      "Batch Prediction Results:\n",
      "\n",
      "Email: Congratulations! You won a brand new MacBook. Click here to claim ðŸŽ‰\n",
      "Predicted Label: spam, Probability: 0.918\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Dear friend, I hope this email finds you well. Can we meet tomorrow?\n",
      "Predicted Label: ham, Probability: 0.010\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: URGENT: Verify your bank account immediately to avoid suspension!\n",
      "Predicted Label: spam, Probability: 0.811\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Limited time offer! Buy 2 get 1 free on all electronics.\n",
      "Predicted Label: spam, Probability: 0.292\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Meeting reminder: Project discussion at 10 AM today.\n",
      "Predicted Label: ham, Probability: 0.004\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: You have been selected for a $5000 cash prize. Reply now!\n",
      "Predicted Label: spam, Probability: 0.872\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Happy birthday! Wishing you a wonderful day filled with joy.\n",
      "Predicted Label: ham, Probability: 0.017\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Claim your reward points now before the offer expires ðŸ’¥\n",
      "Predicted Label: spam, Probability: 0.614\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Can you review the attached document and send feedback?\n",
      "Predicted Label: ham, Probability: 0.071\n",
      "--------------------------------------------------\n",
      "\n",
      "Email: Free tickets to the concert! First come first serve!\n",
      "Predicted Label: spam, Probability: 0.064\n",
      "--------------------------------------------------\n",
      "\n",
      "Batch Accuracy: 1.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00         4\n",
      "        spam       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "\n",
      "Model successfully saved to spam_classifier.pkl\n",
      "\n",
      "Model successfully reloaded and ready for prediction.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import requests, zipfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import pickle\n",
    "\n",
    "# --------------------------\n",
    "# NLTK stopwords\n",
    "# --------------------------\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# --------------------------\n",
    "# Helper functions\n",
    "# --------------------------\n",
    "EMOJI_PATTERN = re.compile(\"[\\U0001F300-\\U0001F6FF\\U0001F900-\\U0001F9FF\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
    "def count_emojis(s): return len(EMOJI_PATTERN.findall(str(s)))\n",
    "def count_digits(s): return sum(c.isdigit() for c in str(s))\n",
    "def uppercase_ratio(s):\n",
    "    letters = [c for c in str(s) if c.isalpha()]\n",
    "    return sum(1 for c in letters if c.isupper())/len(letters) if letters else 0\n",
    "def tokenize_simple(s): return re.findall(r\"\\w+\", str(s).lower())\n",
    "\n",
    "# --------------------------\n",
    "# Feature engineering\n",
    "# --------------------------\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['char_count'] = df['message'].str.len()\n",
    "    df['word_count'] = df['message'].apply(lambda s: len(tokenize_simple(s)))\n",
    "    df['digit_count'] = df['message'].apply(count_digits)\n",
    "    df['digit_ratio'] = df['digit_count']/df['char_count'].replace(0,1)\n",
    "    df['emoji_count'] = df['message'].apply(count_emojis)\n",
    "    df['upper_ratio'] = df['message'].apply(uppercase_ratio)\n",
    "    df['punct_count'] = df['message'].apply(lambda s: sum(1 for c in str(s) if c in '!?.,:;'))\n",
    "    df['stopword_count'] = df['message'].apply(lambda s: sum(1 for w in tokenize_simple(s) if w in STOPWORDS))\n",
    "    return df\n",
    "\n",
    "# --------------------------\n",
    "# Load datasets\n",
    "# --------------------------\n",
    "SYNTH_PATH = Path(r\"C:\\Users\\Lohith\\OneDrive\\Desktop\\AI COURSE PROJECTS\\synthetic-clean.csv\")\n",
    "if not SYNTH_PATH.exists(): raise FileNotFoundError(f\"Synthetic dataset not found at {SYNTH_PATH}\")\n",
    "synth_df = pd.read_csv(SYNTH_PATH)\n",
    "synth_df = synth_df.rename(columns={synth_df.columns[0]:'label', synth_df.columns[1]:'message'})\n",
    "synth_df['label'] = synth_df['label'].str.lower()\n",
    "synth_df['message'] = synth_df['message'].astype(str)\n",
    "\n",
    "USER_PATH = Path(r\"C:\\Users\\Lohith\\OneDrive\\Desktop\\AI COURSE PROJECTS\\spam.csv\")\n",
    "if not USER_PATH.exists(): raise FileNotFoundError(f\"User dataset not found at {USER_PATH}\")\n",
    "user_df = pd.read_csv(USER_PATH, encoding='latin-1')\n",
    "if 'message' not in user_df.columns:\n",
    "    for c in user_df.columns:\n",
    "        if 'message' in c.lower() or 'text' in c.lower():\n",
    "            user_df.rename(columns={c:'message'}, inplace=True)\n",
    "if 'label' not in user_df.columns:\n",
    "    for c in user_df.columns:\n",
    "        if user_df[c].astype(str).str.lower().isin(['ham','spam']).all():\n",
    "            user_df.rename(columns={c:'label'}, inplace=True)\n",
    "user_df = user_df[['label','message']]\n",
    "user_df['label'] = user_df['label'].str.lower()\n",
    "user_df['message'] = user_df['message'].astype(str)\n",
    "\n",
    "# --------------------------\n",
    "# Download UCI dataset\n",
    "# --------------------------\n",
    "UCI_ZIP_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "resp = requests.get(UCI_ZIP_URL, timeout=30)\n",
    "resp.raise_for_status()\n",
    "with zipfile.ZipFile(BytesIO(resp.content)) as z:\n",
    "    with z.open('SMSSpamCollection') as f:\n",
    "        uci_data = f.read().decode('utf-8')\n",
    "rows = [line.split('\\t',1) for line in uci_data.splitlines() if line.strip()]\n",
    "uci_df = pd.DataFrame(rows, columns=['label','message'])\n",
    "uci_df['label'] = uci_df['label'].str.lower()\n",
    "uci_df['message'] = uci_df['message'].astype(str)\n",
    "\n",
    "# --------------------------\n",
    "# Generate OTP + emoji spam\n",
    "# --------------------------\n",
    "def make_otp_samples(n=300):\n",
    "    samples = []\n",
    "    banks = ['HDFC','SBI','ICICI','Axis','Bank','YourBank']\n",
    "    for _ in range(n):\n",
    "        otp = ''.join(str(random.randint(0,9)) for _ in range(random.choice([4,5,6])))\n",
    "        bank = random.choice(banks)\n",
    "        if random.random()<0.5:\n",
    "            s = f\"{bank}: Your OTP is {otp}. Do not share this with anyone.\"\n",
    "        else:\n",
    "            s = f\"URGENT! Verify your account now using OTP {otp} to avoid suspension. Reply now.\"\n",
    "        samples.append(('spam',s))\n",
    "    return samples\n",
    "\n",
    "emoji_spams = [\n",
    "    ('spam',\"WIN ðŸŽ‰ðŸŽ! You have won a prize worth $1000. Click http://bit.ly/win-now\"),\n",
    "    ('spam',\"Congratulations! ðŸŽ‰ Claim your â‚¹5000 cashback now ðŸ’µ. Reply YES to claim\"),\n",
    "    ('spam',\"LIMITED OFFER ðŸ’¥ Buy 1 get 1 FREE. Visit our site now!\")\n",
    "]\n",
    "\n",
    "otp_samples = make_otp_samples(400)\n",
    "synth_otp_emoji_df = pd.DataFrame(otp_samples + emoji_spams, columns=['label','message'])\n",
    "\n",
    "# --------------------------\n",
    "# Combine all datasets\n",
    "# --------------------------\n",
    "combined = pd.concat([synth_df, user_df, uci_df, synth_otp_emoji_df], ignore_index=True)\n",
    "combined['message'] = combined['message'].astype(str)\n",
    "\n",
    "# Balance ham and spam\n",
    "counts = combined['label'].value_counts()\n",
    "n_ham, n_spam = counts.get('ham',0), counts.get('spam',0)\n",
    "if n_spam < n_ham:\n",
    "    needed = n_ham - n_spam\n",
    "    spam_pool = combined[combined['label']=='spam']\n",
    "    sampled = spam_pool.sample(n=needed, replace=True, random_state=42)\n",
    "    combined = pd.concat([combined, sampled], ignore_index=True)\n",
    "elif n_ham < n_spam:\n",
    "    needed = n_spam - n_ham\n",
    "    ham_pool = combined[combined['label']=='ham']\n",
    "    sampled = ham_pool.sample(n=needed, replace=True, random_state=42)\n",
    "    combined = pd.concat([combined, sampled], ignore_index=True)\n",
    "\n",
    "# --------------------------\n",
    "# Feature engineering\n",
    "# --------------------------\n",
    "combined_feat = add_features(combined)\n",
    "num_cols = ['char_count','word_count','digit_count','digit_ratio','emoji_count','upper_ratio','punct_count','stopword_count']\n",
    "\n",
    "# --------------------------\n",
    "# Train/test split\n",
    "# --------------------------\n",
    "X_text = combined_feat['message'].values\n",
    "y = combined_feat['label'].map({'ham':0,'spam':1}).values\n",
    "X_train_text, X_test_text, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X_text, y, np.arange(len(y)), test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train_num = csr_matrix(combined_feat.iloc[train_idx][num_cols].values)\n",
    "X_test_num = csr_matrix(combined_feat.iloc[test_idx][num_cols].values)\n",
    "\n",
    "X_train = hstack([X_train_tfidf, X_train_num])\n",
    "X_test = hstack([X_test_tfidf, X_test_num])\n",
    "\n",
    "# --------------------------\n",
    "# Train Logistic Regression\n",
    "# --------------------------\n",
    "clf = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "probs = clf.predict_proba(X_test)[:,1]\n",
    "preds = (probs >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nEvaluation on test set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, probs))\n",
    "print(classification_report(y_test, preds, target_names=['ham','spam']))\n",
    "\n",
    "# --------------------------\n",
    "# Prepare batch function\n",
    "# --------------------------\n",
    "def prepare_batch(emails):\n",
    "    df = pd.DataFrame({'message': emails})\n",
    "    df_feat = add_features(df)\n",
    "    X_text_batch = vectorizer.transform(df_feat['message'])\n",
    "    X_num_batch = csr_matrix(df_feat[num_cols].values)\n",
    "    X_batch = hstack([X_text_batch, X_num_batch])\n",
    "    return X_batch\n",
    "\n",
    "# --------------------------\n",
    "# Batch Prediction\n",
    "# --------------------------\n",
    "SPAM_KEYWORDS = ['offer','win','cash','prize','free','click','urgent','limited','buy now','reward','claim']\n",
    "\n",
    "def predict_spam_batch(emails, clf, threshold=0.2):\n",
    "    X_batch = prepare_batch(emails)\n",
    "    probs = clf.predict_proba(X_batch)[:,1]\n",
    "    preds = []\n",
    "    for email, prob in zip(emails, probs):\n",
    "        email_lower = email.lower()\n",
    "        if prob >= threshold or any(k in email_lower for k in SPAM_KEYWORDS):\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return preds, probs\n",
    "\n",
    "# --------------------------\n",
    "# Runtime testing\n",
    "# --------------------------\n",
    "emails_batch = [\n",
    "    \"Congratulations! You won a brand new MacBook. Click here to claim ðŸŽ‰\",\n",
    "    \"Dear friend, I hope this email finds you well. Can we meet tomorrow?\",\n",
    "    \"URGENT: Verify your bank account immediately to avoid suspension!\",\n",
    "    \"Limited time offer! Buy 2 get 1 free on all electronics.\",\n",
    "    \"Meeting reminder: Project discussion at 10 AM today.\",\n",
    "    \"You have been selected for a $5000 cash prize. Reply now!\",\n",
    "    \"Happy birthday! Wishing you a wonderful day filled with joy.\",\n",
    "    \"Claim your reward points now before the offer expires ðŸ’¥\",\n",
    "    \"Can you review the attached document and send feedback?\",\n",
    "    \"Free tickets to the concert! First come first serve!\"\n",
    "]\n",
    "\n",
    "true_labels = [1,0,1,1,0,1,0,1,0,1]  # 1=spam, 0=ham\n",
    "\n",
    "batch_preds, batch_probs = predict_spam_batch(emails_batch, clf)\n",
    "\n",
    "print(\"\\nBatch Prediction Results:\")\n",
    "for email, pred, prob in zip(emails_batch, batch_preds, batch_probs):\n",
    "    label = 'spam' if pred==1 else 'ham'\n",
    "    print(f\"\\nEmail: {email}\")\n",
    "    print(f\"Predicted Label: {label}, Probability: {prob:.3f}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, batch_preds)\n",
    "print(f\"\\nBatch Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, batch_preds, target_names=['ham','spam']))\n",
    "\n",
    "# --------------------------\n",
    "# Save model, vectorizer, and numeric column info\n",
    "# --------------------------\n",
    "model_filename = \"spam_classifier.pkl\"\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        'model': clf,\n",
    "        'vectorizer': vectorizer,\n",
    "        'num_cols': num_cols\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nModel successfully saved to {model_filename}\")\n",
    "\n",
    "# --------------------------\n",
    "# Load the model later\n",
    "# --------------------------\n",
    "with open(model_filename, \"rb\") as f:\n",
    "    saved = pickle.load(f)\n",
    "\n",
    "clf_loaded = saved['model']\n",
    "vectorizer_loaded = saved['vectorizer']\n",
    "num_cols_loaded = saved['num_cols']\n",
    "\n",
    "print(\"\\nModel successfully reloaded and ready for prediction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661250ea-81af-41c2-940d-0663ae1c0dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Email Test:\n",
      "Email: Win a free iPhone now! ðŸŽ‰\n",
      "Predicted Label: spam, Probability: 0.681\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congratulations! You won a brand new MacBook. ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear friend, I hope this email finds you well....</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URGENT: Verify your bank account immediately t...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meeting reminder: Project discussion at 10 AM ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email Predicted Label  \\\n",
       "0  Congratulations! You won a brand new MacBook. ...            spam   \n",
       "1  Dear friend, I hope this email finds you well....             ham   \n",
       "2  URGENT: Verify your bank account immediately t...            spam   \n",
       "3  Meeting reminder: Project discussion at 10 AM ...             ham   \n",
       "\n",
       "   Probability  \n",
       "0        0.918  \n",
       "1        0.010  \n",
       "2        0.811  \n",
       "3        0.004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# --------------------------\n",
    "# Single email prediction\n",
    "# --------------------------\n",
    "def predict_single_email(email, clf, vectorizer, num_cols, threshold=0.2):\n",
    "    df = pd.DataFrame({'message': [email]})\n",
    "    df_feat = add_features(df)\n",
    "    X_text = vectorizer.transform(df_feat['message'])\n",
    "    X_num = csr_matrix(df_feat[num_cols].values)\n",
    "    X = hstack([X_text, X_num])\n",
    "\n",
    "    prob = clf.predict_proba(X)[0,1]\n",
    "    label = \"spam\" if prob >= threshold else \"ham\"\n",
    "    return label, prob\n",
    "\n",
    "# --------------------------\n",
    "# Batch prediction\n",
    "# --------------------------\n",
    "def predict_spam_batch(emails, clf, vectorizer, num_cols, threshold=0.2):\n",
    "    df = pd.DataFrame({'message': emails})\n",
    "    df_feat = add_features(df)\n",
    "    X_text_batch = vectorizer.transform(df_feat['message'])\n",
    "    X_num_batch = csr_matrix(df_feat[num_cols].values)\n",
    "    X_batch = hstack([X_text_batch, X_num_batch])\n",
    "\n",
    "    probs = clf.predict_proba(X_batch)[:,1]\n",
    "    preds = [\"spam\" if p >= threshold else \"ham\" for p in probs]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Email\": emails,\n",
    "        \"Predicted Label\": preds,\n",
    "        \"Probability\": probs.round(3)\n",
    "    })\n",
    "\n",
    "# --------------------------\n",
    "# Test single email\n",
    "# --------------------------\n",
    "email = \"Win a free iPhone now! ðŸŽ‰\"\n",
    "label, prob = predict_single_email(email, clf_loaded, vectorizer_loaded, num_cols_loaded)\n",
    "print(f\"Single Email Test:\\nEmail: {email}\\nPredicted Label: {label}, Probability: {prob:.3f}\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# Test batch emails\n",
    "# --------------------------\n",
    "batch_emails = [\n",
    "    \"Congratulations! You won a brand new MacBook. Click here to claim ðŸŽ‰\",\n",
    "    \"Dear friend, I hope this email finds you well. Can we meet tomorrow?\",\n",
    "    \"URGENT: Verify your bank account immediately to avoid suspension!\",\n",
    "    \"Meeting reminder: Project discussion at 10 AM today.\"\n",
    "]\n",
    "\n",
    "results = predict_spam_batch(batch_emails, clf_loaded, vectorizer_loaded, num_cols_loaded)\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ea8d7-50bc-481d-adb3-614cfb674abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Single email runtime input\n",
    "# --------------------------\n",
    "email = input(\"Enter a single email to classify: \")\n",
    "\n",
    "label, prob = predict_single_email(email, clf_loaded, vectorizer_loaded, num_cols_loaded)\n",
    "print(f\"\\nSingle Email Test:\")\n",
    "print(f\"Email: {email}\")\n",
    "print(f\"Predicted Label: {label}, Probability: {prob:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Batch runtime input\n",
    "# --------------------------\n",
    "emails_text = input(\"\\nEnter multiple emails separated by ';':\\n\")\n",
    "batch_emails = [e.strip() for e in emails_text.split(\";\") if e.strip()]\n",
    "\n",
    "if batch_emails:\n",
    "    print(\"\\nBatch Prediction Results:\")\n",
    "    results = predict_spam_batch(batch_emails, clf_loaded, vectorizer_loaded, num_cols_loaded)\n",
    "    display(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
